{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import collections\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn import svm\n",
    "from sklearn.metrics import classification_report\n",
    "#from sklearn.model_selection import ShuffleSplit\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "#from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classifaction_report_dataFrame(report):\n",
    "    report_data = pd.DataFrame()\n",
    "    lines = report.split('\\n')\n",
    "    for line in lines[2:-3]:\n",
    "        row = {}\n",
    "        row_data = line.split('      ')\n",
    "        report_data = report_data.append({\"class\": row_data[0], \"precision\": float(row_data[1]), \"recall\": float(row_data[2]), \"f1_score\": float(row_data[3])}, ignore_index=True)\n",
    "    return report_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [],
   "source": [
    "#split (0.8 train_data 0.2 test_data)\n",
    "\n",
    "def prepereDataWithoutLemmatisation(split):\n",
    "    data = np.empty((0))\n",
    "    data_labels = np.empty((0))\n",
    "\n",
    "    comments = pd.read_csv('FilmWeb-commentsRates.csv')\n",
    "    comments = comments.reset_index()\n",
    "    comments.loc[comments.emotion == 'neutral', 'emotion'] = \"negative\"\n",
    "    \n",
    "    train_data = pd.DataFrame()\n",
    "    test_data = pd.DataFrame()\n",
    "\n",
    "    length_train_data = int(split * len(comments))\n",
    "    train_data = comments[:length_train_data]\n",
    "    test_data = comments[length_train_data:]\n",
    "  \n",
    "    for index, train_data in train_data.iterrows():\n",
    "        data = np.append(data, train_data['Text'])\n",
    "        data_labels = np.append(data_labels, train_data['emotion'])\n",
    "    return [data, data_labels, test_data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepereDataWithLemmatisation(split):\n",
    "    data = np.empty((0))\n",
    "    data_labels = np.empty((0))\n",
    "    \n",
    "    comments = pd.read_csv('FilmWeb-lemmatisation-commentsRates.csv')\n",
    "    comments = comments.reset_index()\n",
    "    comments.loc[comments.emotion == 'neutral', 'emotion'] = \"negative\"\n",
    "    \n",
    "    for index, comment in comments.iterrows():\n",
    "        data = np.append(data, comment['comment'])\n",
    "        data_labels = np.append(data_labels, comment['emotion'])\n",
    "    return [data, data_labels]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SVM(iterations, dataset, is_shuffle):\n",
    "    data = dataset[0]\n",
    "    data_labels = dataset[1]\n",
    "    report_data_Linear = pd.DataFrame()\n",
    "    report_data_Liblinear = pd.DataFrame()\n",
    "    report_data_Liblinear2 = pd.DataFrame()\n",
    "\n",
    "    #Some classification problems can exhibit a large imbalance in the distribution of the target classes: \n",
    "    #for instance there could be several times more negative samples than positive samples.\n",
    "    #StratifiedKFold is a variation of k-fold which returns stratified folds: each set contains approximately \n",
    "    #the same percentage of samples of each target class as the complete set.\n",
    "    #K-krotna walidacja\n",
    "    \n",
    "    #shuffle - przetasowanie zbiorów\n",
    "    sss = StratifiedKFold(n_splits=iterations, shuffle=is_shuffle)\n",
    "    classifier_liblinear2 = svm.LinearSVC()\n",
    "    for train_index, test_index in sss.split(data, data_labels):\n",
    "        train_data, test_data = data[train_index], data[test_index]\n",
    "        train_labels, test_labels = data_labels[train_index], data_labels[test_index]\n",
    "\n",
    "        # Create feature vectors\n",
    "        \n",
    "        #min_df - When building the vocabulary ignore terms that have a document frequency strictly lower \n",
    "        #than the given threshold. This value is also called cut-off in the literature.\n",
    "        #If float, the parameter represents a proportion of documents, integer absolute counts.\n",
    "        #This parameter is ignored if vocabulary is not None.\n",
    "        \n",
    "        vectorizer = TfidfVectorizer(min_df=5,max_df = 0.8,sublinear_tf=True,use_idf=True)\n",
    "        train_vectors = vectorizer.fit_transform(train_data)\n",
    "        test_vectors = vectorizer.transform(test_data)\n",
    "\n",
    "        # Perform classification with SVM, kernel=linear\n",
    "        classifier_linear = svm.SVC(kernel='linear')\n",
    "        t0 = time.time()\n",
    "        classifier_linear.fit(train_vectors, train_labels)\n",
    "        t1 = time.time()\n",
    "        prediction_linear = classifier_linear.predict(test_vectors)\n",
    "        t2 = time.time()\n",
    "        time_linear_train = t1-t0\n",
    "        time_linear_predict = t2-t1\n",
    "\n",
    "        # Perform classification with SVM, kernel=linear\n",
    "        classifier_liblinear = svm.LinearSVC()\n",
    "        t0 = time.time()\n",
    "        classifier_liblinear.fit(train_vectors, train_labels)\n",
    "        t1 = time.time()\n",
    "        prediction_liblinear = classifier_liblinear.predict(test_vectors)\n",
    "        t2 = time.time()\n",
    "        time_liblinear_train = t1-t0\n",
    "        time_liblinear_predict = t2-t1\n",
    "        \n",
    "        # Perform classification with SVM, kernel=linear\n",
    "        t0 = time.time()\n",
    "        classifier_liblinear2.fit(train_vectors, train_labels)\n",
    "        t1 = time.time()\n",
    "        prediction_liblinear2 = classifier_liblinear.predict(test_vectors)\n",
    "        t2 = time.time()\n",
    "        time_liblinear_train2 = t1-t0\n",
    "        time_liblinear_predict2 = t2-t1\n",
    "\n",
    "        reportLinear = classification_report(test_labels, prediction_linear)\n",
    "        reportLiblinear2 = classification_report(test_labels, prediction_liblinear2)\n",
    "        \n",
    "        lines = reportLinear.split('\\n')\n",
    "        for line in lines[2:-3]:\n",
    "            row = {}\n",
    "            row_data = line.split('      ')\n",
    "            report_data_Linear = report_data_Linear.append({\"class\": row_data[0], \"precision\": float(row_data[1]), \"recall\": float(row_data[2]), \"f1_score\": float(row_data[3]), \"support\": float(row_data[4])}, ignore_index=True)\n",
    "\n",
    "        lines = reportLiblinear.split('\\n')\n",
    "        for line in lines[2:-3]:\n",
    "            row = {}\n",
    "            row_data = line.split('      ')\n",
    "            report_data_Liblinear = report_data_Liblinear.append({\"class\": row_data[0], \"precision\": float(row_data[1]), \"recall\": float(row_data[2]), \"f1_score\": float(row_data[3]), \"support\": float(row_data[4])}, ignore_index=True)\n",
    "        \n",
    "        lines = reportLiblinear2.split('\\n')\n",
    "        for line in lines[2:-3]:\n",
    "            row = {}\n",
    "            row_data = line.split('      ')\n",
    "            report_data_Liblinear2 = report_data_Liblinear2.append({\"class\": row_data[0], \"precision\": float(row_data[1]), \"recall\": float(row_data[2]), \"f1_score\": float(row_data[3]), \"support\": float(row_data[4])}, ignore_index=True)\n",
    "        \n",
    "    print 'Training data:'\n",
    "    counter=collections.Counter(train_labels)\n",
    "    print(counter)\n",
    "\n",
    "    print 'Test data:'\n",
    "    counter=collections.Counter(test_labels)\n",
    "    print(counter)\n",
    "    \n",
    "    return [report_data_Liblinear, report_data_Linear, report_data_Liblinear2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iterations = 10\n",
    "shuffle = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#SVM without Lemmatisation\n",
    "dataset = prepereDataWithoutLemmatisation()\n",
    "\n",
    "print 'number of dataset: ' + str(iterations)\n",
    "data = SVM(iterations, dataset, shuffle)\n",
    "print 'Linear report:'\n",
    "printReportLinear(data)\n",
    "print 'Liblinear report:'\n",
    "printReportLiblinear(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#SVM with Lemmatisation\n",
    "dataset = prepereDataWithLemmatisation()\n",
    "\n",
    "print 'number of dataset: ' + str(iterations)\n",
    "data = SVM(iterations, dataset, shuffle)\n",
    "print 'Linear report:'\n",
    "printReportLinear(data)\n",
    "print 'Liblinear report:'\n",
    "printReportLiblinear(data)\n",
    "\n",
    "print 'Liblinear2 report:'\n",
    "printReportLiblinear2(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def printReportLiblinear(dataframe):\n",
    "    liblinear = dataframe[1]\n",
    "    for index, data in liblinear.groupby('class'):\n",
    "        print(data)\n",
    "        \n",
    "def printReportLiblinear2(dataframe):\n",
    "    liblinear = dataframe[2]\n",
    "    for index, data in liblinear.groupby('class'):\n",
    "        print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def printReportLinear(dataframe):\n",
    "    linear = dataframe[0]\n",
    "    for index, data in linear.groupby('class'):\n",
    "        print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SVM_liblinear(iterations, dataset, is_shuffle):\n",
    "    data = dataset[0]\n",
    "    data_labels = dataset[1]\n",
    "    \n",
    "    sss = StratifiedKFold(n_splits=iterations, shuffle=is_shuffle)\n",
    "\n",
    "    for train_index, test_index in sss.split(data, data_labels):\n",
    "        train_data = data[train_index]\n",
    "        train_labels = data_labels[train_index]\n",
    "        \n",
    "        vectorizer = TfidfVectorizer(min_df=5,max_df = 0.8,sublinear_tf=True,use_idf=True)\n",
    "        train_vectors = vectorizer.fit_transform(train_data)\n",
    "        \n",
    "        classifier_liblinear = svm.LinearSVC()\n",
    "        classifier_liblinear.fit(train_vectors, train_labels)\n",
    "        \n",
    "    return [classifier_liblinear,vectorizer]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {},
   "outputs": [],
   "source": [
    "#testing dataset\n",
    "\n",
    "iterations = 10\n",
    "shuffle = True\n",
    "dataset = prepereDataWithoutLemmatisation(0.8)\n",
    "[classifier, vectorizer] = SVM_liblinear(iterations, dataset, shuffle)\n",
    "testData = dataset[2]\n",
    "detectedEmotion = SCV_detectingEmotions(classifier,vectorizer,testData['Text'])\n",
    "\n",
    "result_df = pd.DataFrame({\"text\": testData['Text'], \"detectedEmotion\": detectedEmotion, 'emotion': testData['emotion']})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepereTestData(maximumNegativeRate, mimimumPositiveRate, ):\n",
    "    comments = pd.read_csv('FilmWeb-commentsRates.csv')\n",
    "    comments.loc[comments.emotion == 'neutral', 'emotion'] = \"negative\"\n",
    "    comments = comments[(comments.rate <= maximumNegativeRate) | (comments.rate >= mimimumPositiveRate)]\n",
    "    comments = comments.reset_index()\n",
    "    #charToRemove= dict.fromkeys('!@#$?.:,')\n",
    "   # comments['Text'] = comments['Text'].translate(charToRemove)\n",
    "    return comments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SCV_detectingEmotions(classifier, vectorizer, test_data):\n",
    "    test_vectors = vectorizer.transform(test_data)\n",
    "    prediction_liblinear = classifier.predict(test_vectors)\n",
    "    return prediction_liblinear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1a17c17ed0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "def get_length(text):\n",
    "    return len(text)\n",
    "\n",
    "def get_length_bin(length):\n",
    "    return length / 10\n",
    "\n",
    "def get_score(result):\n",
    "    return 1 if result else 0\n",
    "\n",
    "result_df['correct_guess'] = result_df['detectedEmotion'] == result_df['emotion']\n",
    "result_df['score'] = map(get_score, result_df['correct_guess'])\n",
    "result_df['text_length'] = map(get_length, result_df['text'])\n",
    "result_df['text_length_bin'] = map(get_length_bin, result_df['text_length'])\n",
    "grouped = result_df.groupby('text_length_bin', as_index=False)['score'].mean()\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "x = grouped.text_length_bin * 10\n",
    "y = grouped.score\n",
    "fit = np.polyfit(x, y, deg=1)\n",
    "ax.plot(x, fit[0] * x + fit[1], color='red')\n",
    "ax.scatter(x, y)\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of correct guess: 578\n",
      "Number of wrong guess: 313\n"
     ]
    }
   ],
   "source": [
    "print 'Number of correct guess: ' + str(len(result_df.loc[result_df['correct_guess'] == True]))\n",
    "print 'Number of wrong guess: ' + str(len(result_df.loc[result_df['correct_guess'] == False]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = result_df.head(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>detectedEmotion</th>\n",
       "      <th>emotion</th>\n",
       "      <th>text</th>\n",
       "      <th>correct_guess</th>\n",
       "      <th>score</th>\n",
       "      <th>text_length</th>\n",
       "      <th>text_length_bin</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>negative</td>\n",
       "      <td>negative</td>\n",
       "      <td>\"Boże, zaraz się zrzygam\"..                   ...</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>479</td>\n",
       "      <td>47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>negative</td>\n",
       "      <td>negative</td>\n",
       "      <td>Film dla \"ajfonowych\" lemingów z ujemnym IQ.  ...</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>307</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>negative</td>\n",
       "      <td>negative</td>\n",
       "      <td>To najbardziej antyfeministyczna rzecz w dziej...</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>473</td>\n",
       "      <td>47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>negative</td>\n",
       "      <td>negative</td>\n",
       "      <td>Prawdziwy dramat                        Na wst...</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>462</td>\n",
       "      <td>46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>negative</td>\n",
       "      <td>negative</td>\n",
       "      <td>Film                         Za mało Złotych M...</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>68</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>negative</td>\n",
       "      <td>negative</td>\n",
       "      <td>Hmm... budżet: 40 000 000 $                   ...</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>163</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>negative</td>\n",
       "      <td>negative</td>\n",
       "      <td>Połączenie komedii romantycznej z soft porno. ...</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>466</td>\n",
       "      <td>46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>negative</td>\n",
       "      <td>negative</td>\n",
       "      <td>Chciałabym odzobaczyć                        f...</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>360</td>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>negative</td>\n",
       "      <td>negative</td>\n",
       "      <td>\"Boże, zaraz się zrzygam\"..Słowa Koroniewskiej...</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>442</td>\n",
       "      <td>44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>negative</td>\n",
       "      <td>negative</td>\n",
       "      <td>Film dla \"ajfonowych\" lemingów z ujemnym IQ.Te...</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>269</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  detectedEmotion   emotion  \\\n",
       "0        negative  negative   \n",
       "1        negative  negative   \n",
       "2        negative  negative   \n",
       "3        negative  negative   \n",
       "4        negative  negative   \n",
       "5        negative  negative   \n",
       "6        negative  negative   \n",
       "7        negative  negative   \n",
       "8        negative  negative   \n",
       "9        negative  negative   \n",
       "\n",
       "                                                text  correct_guess  score  \\\n",
       "0  \"Boże, zaraz się zrzygam\"..                   ...           True      1   \n",
       "1  Film dla \"ajfonowych\" lemingów z ujemnym IQ.  ...           True      1   \n",
       "2  To najbardziej antyfeministyczna rzecz w dziej...           True      1   \n",
       "3  Prawdziwy dramat                        Na wst...           True      1   \n",
       "4  Film                         Za mało Złotych M...           True      1   \n",
       "5  Hmm... budżet: 40 000 000 $                   ...           True      1   \n",
       "6  Połączenie komedii romantycznej z soft porno. ...           True      1   \n",
       "7  Chciałabym odzobaczyć                        f...           True      1   \n",
       "8  \"Boże, zaraz się zrzygam\"..Słowa Koroniewskiej...           True      1   \n",
       "9  Film dla \"ajfonowych\" lemingów z ujemnym IQ.Te...           True      1   \n",
       "\n",
       "   text_length  text_length_bin  \n",
       "0          479               47  \n",
       "1          307               30  \n",
       "2          473               47  \n",
       "3          462               46  \n",
       "4           68                6  \n",
       "5          163               16  \n",
       "6          466               46  \n",
       "7          360               36  \n",
       "8          442               44  \n",
       "9          269               26  "
      ]
     },
     "execution_count": 287,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "first_ten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createCommentsWithLemmatisation():\n",
    "    commentsWithLemmatisation = pd.DataFrame()\n",
    "    comments = pd.read_csv('FilmWeb-commentsRates.csv')\n",
    "    for comment in comments:\n",
    "        print(comment)\n",
    "        #text = lemmatisation(comment['Text'])\n",
    "        #commentsWithLemmatisation = commentsWithLemmatisation.append({'text': ''.join(text), 'emotion': comment['emotion'], 'rate': comment['rate']}, ignore_index=True)\n",
    "    #return commentsWithLemmatisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text\n",
      "emotion\n",
      "rate\n"
     ]
    }
   ],
   "source": [
    "createCommentsWithLemmatisation()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
